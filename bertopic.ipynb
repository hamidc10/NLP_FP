{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/anna19/Conda_Env/nlp2023v2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports compelete\n"
     ]
    }
   ],
   "source": [
    "# installs\n",
    "# !pip install bertopic \n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from bertopic import BERTopic\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# from bertopic import preprocess_text\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from tokenizers import pre_tokenizers\n",
    "# nltk.download('stopwords')\n",
    "    \n",
    "print(\"imports compelete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electronics done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## Download and decompress data\n",
    "\n",
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Books_5.json.gz\n",
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Home_and_Kitchen_5.json.gz\n",
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Sports_and_Outdoors_5.json.gz\n",
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Electronics_5.json.gz\n",
    "\n",
    "import gzip\n",
    "chunk_size=5 * 1024 * 1024\n",
    "\n",
    "with gzip.open('Books_5.json.gz') as f:\n",
    "    with open(\"Books_5.json\", 'wb') as f_out:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            f_out.write(chunk)\n",
    "print(\"books done\")\n",
    "\n",
    "with gzip.open('Home_and_Kitchen_5.json.gz') as f:\n",
    "    with open(\"Home_and_Kitchen_5.json\", 'wb') as f_out:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            f_out.write(chunk)\n",
    "print(\"kitchen done\")\n",
    "\n",
    "with gzip.open('Sports_and_Outdoors_5.json.gz') as f:\n",
    "    with open(\"Sports_and_Outdoors_5.json\", 'wb') as f_out:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            f_out.write(chunk)\n",
    "print(\"sports done\")\n",
    "\n",
    "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Electronics_5.json.gz\n",
    "\n",
    "with gzip.open(\"Electronics_5.json.gz\", 'rb') as f:\n",
    "    with open(\"Electronics_5.json\", 'wb') as f_out:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            f_out.write(chunk)\n",
    "print(\"electronics done\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdoors done\n",
      "CPU times: user 13.6 s, sys: 1.41 s, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# store data in lists\n",
    "\n",
    "import json\n",
    "\n",
    "review_text = []\n",
    "\n",
    "training_data_books = []\n",
    "training_data_outdoors = []\n",
    "training_data_electronics = []\n",
    "training_data_kitchen=[]\n",
    "# with open('Books_5.json') as f:\n",
    "#     for review in f:\n",
    "#         text = json.loads(review).get(\"reviewText\", \"\").strip()\n",
    "#         summary = json.loads(review).get(\"summary\", \"\").strip()\n",
    "#         review = summary + \" \" + text\n",
    "#         if review.strip():\n",
    "#             training_data_books.append(review)\n",
    "# print(\"Books done\")\n",
    "    \n",
    "# with open('Home_and_Kitchen_5.json') as f:\n",
    "#     for review in f:\n",
    "#         review = json.loads(review)\n",
    "#         text = review.get(\"reviewText\", \"\").strip()\n",
    "#         summary = review.get(\"summary\", \"\").strip()\n",
    "#         review = summary + \" \" + text\n",
    "#         if review.strip():\n",
    "#             training_data_kitchen.append(review)\n",
    "            \n",
    "# print(\"kitchen done\")\n",
    "\n",
    "with open('Sports_and_Outdoors_5.json') as f:\n",
    "    for review in f:\n",
    "        review = json.loads(review)\n",
    "        text = review.get(\"reviewText\", \"\").strip()\n",
    "        summary = review.get(\"summary\", \"\").strip()\n",
    "        review = summary + \" \" + text\n",
    "        if review.strip():\n",
    "            training_data_outdoors.append(review)\n",
    "            \n",
    "print(\"outdoors done\")\n",
    "\n",
    "# with open('Electronics_5.json') as f:\n",
    "#     for review in f:\n",
    "#         review = json.loads(review)\n",
    "#         text = review.get(\"reviewText\", \"\").strip()\n",
    "#         summary = review.get(\"summary\", \"\").strip()\n",
    "#         review = summary + \" \" + text\n",
    "#         if review.strip():\n",
    "#             training_data_electronics.append(review)\n",
    "# print(\"electronics done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%time is a cell magic, but the cell body is empty. Did you mean the line magic %time (single %)?\n"
     ]
    }
   ],
   "source": [
    "%%time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read in\n",
      "500000\n",
      "Five Stars What a spectacular tutu! Very slimming.\n"
     ]
    }
   ],
   "source": [
    "# take 80% of each dataset for training\n",
    "\n",
    "complete_test=[]\n",
    "# complete_test.extend(training_data_books[:int(0.8*len(training_data_books))])\n",
    "# complete_test.extend(training_data_electronics[:int(0.8*len(training_data_electronics))])\n",
    "complete_test.extend(training_data_outdoors[:int(0.8*len(training_data_outdoors))])\n",
    "# complete_test.extend(training_data_kitchen[:int(0.8*len(training_data_kitchen))])\n",
    "    \n",
    "complete_test=complete_test[:500000]\n",
    "            \n",
    "print(\"data read in\")\n",
    "print(len(complete_test))\n",
    "# print(len(training_data_outdoors))\n",
    "print(complete_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 15625/15625 [03:25<00:00, 76.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings done\n",
      "CPU times: user 3min 17s, sys: 18.6 s, total: 3min 35s\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'  # You can specify the GPU device index\n",
    "    print(\"using gpu\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "\n",
    "# Compute embeddings using GPU\n",
    "embeddings = model.encode(complete_test, device=device, show_progress_bar=True)\n",
    "\n",
    "\n",
    "print(\"embeddings done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process begun\n",
      "training data amount: 500000\n",
      "training data amount: 500000\n",
      "model created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 21:11:36,711 - BERTopic - Reduced dimensionality\n",
      "2023-11-21 21:12:38,126 - BERTopic - Clustered reduced embeddings\n",
      "/data/user/anna19/Conda_Env/nlp2023v2/lib/python3.10/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning:\n",
      "\n",
      "Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model done\n",
      "CPU times: user 9h 56min 11s, sys: 4min 45s, total: 10h 56s\n",
      "Wall time: 1h 26min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train and save model\n",
    "# reference: https://maartengr.github.io/BERTopic/getting_started/best_practices/best_practices.html\n",
    "# reference: https://medium.com/rapids-ai/faster-topic-modeling-with-bertopic-and-rapids-cuml-5c7559aba898\n",
    "# https://towardsdatascience.com/topic-modeling-with-lsa-plsa-lda-nmf-bertopic-top2vec-a-comparison-5e6ce4b1e4a5\n",
    "\n",
    "print(\"process begun\")\n",
    "print(f\"training data amount: {len(complete_test)}\")\n",
    "# !pip install \\\n",
    "#     --extra-index-url=https://pypi.nvidia.com \\\n",
    "#     cudf-cu12 dask-cudf-cu12 cuml-cu12 cugraph-cu12 cuspatial-cu12 cuproj-cu12 cuxfilter-cu12 cucim\n",
    "# !pip uninstall cupy-cuda115\n",
    "# !pip install cupy-cuda11x\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from cuml.cluster import HDBSCAN\n",
    "# from cuml.manifold import UMAP\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "# import openai\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, OpenAI, PartOfSpeech\n",
    "\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=150, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "print(f\"training data amount: {len(complete_test)}\")\n",
    "\n",
    "\n",
    "# we add this to remove stopwords\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\", min_df = 2)\n",
    "\n",
    "\n",
    "# KeyBERT\n",
    "keybert_model = KeyBERTInspired()\n",
    "\n",
    "# Part-of-Speech\n",
    "pos_model = PartOfSpeech(\"en_core_web_sm\")\n",
    "\n",
    "# MMR\n",
    "mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "# GPT-3.5\n",
    "# openai.api_key = \"sk-...\"\n",
    "# prompt = \"\"\"\n",
    "# I have a topic that contains the following documents: \n",
    "# [DOCUMENTS]\n",
    "# The topic is described by the following keywords: [KEYWORDS]\n",
    "\n",
    "# Based on the information above, extract a short but highly descriptive topic label of at most 5 words. Make sure it is in the following format:\n",
    "# topic: <topic label>\n",
    "# \"\"\"\n",
    "# openai_model = OpenAI(model=\"gpt-3.5-turbo\", exponential_backoff=True, chat=True, prompt=prompt)\n",
    "\n",
    "# All representation models\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert_model,\n",
    "#     \"OpenAI\": openai_model,  # Uncomment if you will use OpenAI\n",
    "    \"MMR\": mmr_model,\n",
    "    \"POS\": pos_model\n",
    "}\n",
    "\n",
    "bert_model = BERTopic(\n",
    "\n",
    "  # Pipeline models\n",
    "  embedding_model=model,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  vectorizer_model=vectorizer_model,\n",
    "  representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "print(\"model created\")\n",
    "\n",
    "# model = BERTopic(\n",
    "#     vectorizer_model=vectorizer_model,\n",
    "#     hdbscan_model=cluster_model,\n",
    "#     language='english', calculate_probabilities=True,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "topics, probs = bert_model.fit_transform(complete_test, embeddings)\n",
    "\n",
    "bert_model.save(\"bertopic_model_outdoors_500K\")\n",
    "\n",
    "print(\"model done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running again\n"
     ]
    }
   ],
   "source": [
    "# visualize results\n",
    "print(\"running again\")\n",
    "\n",
    "loaded_model = BERTopic.load(\"bertopic_model_outdoors_500K\")\n",
    "\n",
    "loaded_model.visualize_topics().write_html(\"./intertopic_dist_map_outdoors_500K.html\")\n",
    "\n",
    "loaded_model.visualize_barchart(top_n_topics = 25).write_html(\"./barchart_outdoors_500K.html\")\n",
    "\n",
    "# # Save documents projection as HTML file\n",
    "loaded_model.visualize_documents(complete_test).write_html(\"./projections_outdoors_500K.html\")\n",
    "\n",
    "# # Save topics dendrogram as HTML file\n",
    "loaded_model.visualize_hierarchy().write_html(\"./hieararchy_outdoors_500K.html\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Topic  Count                                  Name  \\\n",
      "0      -1   1848              -1_great_board_good_like   \n",
      "1       0   2109  0_stars_stars great_stars good_great   \n",
      "2       1   1097          1_bands_resistance_band_door   \n",
      "3       2    894          2_great_good_quality_product   \n",
      "4       3    486                3_ball_soccer_net_goal   \n",
      "5       4    445         4_stove_coleman_camping_flame   \n",
      "6       5    442            5_scooter_razor_wheels_old   \n",
      "7       6    353              6_frisbee_throw_fun_ring   \n",
      "8       7    349           7_mattress_air_camping_pump   \n",
      "9       8    339          8_compass_bike_suunto_mirror   \n",
      "10      9    337             9_knife_blade_knives_tool   \n",
      "\n",
      "                                       Representation  \\\n",
      "0   [great, board, good, like, just, use, water, s...   \n",
      "1   [stars, stars great, stars good, great, great ...   \n",
      "2   [bands, resistance, band, door, use, great, se...   \n",
      "3   [great, good, quality, product, price, love, w...   \n",
      "4   [ball, soccer, net, goal, balls, basketball, g...   \n",
      "5   [stove, coleman, camping, flame, fuel, gas, co...   \n",
      "6   [scooter, razor, wheels, old, year, loves, yea...   \n",
      "7   [frisbee, throw, fun, ring, catch, aerobie, fl...   \n",
      "8   [mattress, air, camping, pump, inflate, sleepi...   \n",
      "9   [compass, bike, suunto, mirror, bikes, rack, u...   \n",
      "10  [knife, blade, knives, tool, sog, sharp, tools...   \n",
      "\n",
      "                                              KeyBERT  \\\n",
      "0   [batteries, locks, guns, ear, lock, hearing, g...   \n",
      "1   [stars stars, stars, stars great, stars good, ...   \n",
      "2   [resistance bands, resistance band, workouts, ...   \n",
      "3   [quality great, good quality, great quality, q...   \n",
      "4   [soccer ball, soccer balls, ball great, ball, ...   \n",
      "5   [stove, camping, camping trip, coleman product...   \n",
      "6   [scooter great, scooter good, great scooter, g...   \n",
      "7   [best frisbee, frisbee, great frisbee, frisbee...   \n",
      "8   [air mattress, air mattresses, mattress, campi...   \n",
      "9   [compass, gps, lanyard, bearing, hiking, scale...   \n",
      "10  [pocket knife, knife, knives, blade, blades, s...   \n",
      "\n",
      "                                                  MMR  \\\n",
      "0   [great, board, good, like, just, use, water, s...   \n",
      "1   [stars, stars great, stars good, great, great ...   \n",
      "2   [bands, resistance, band, door, use, great, se...   \n",
      "3   [great, good, quality, product, price, love, w...   \n",
      "4   [ball, soccer, net, goal, balls, basketball, g...   \n",
      "5   [stove, coleman, camping, flame, fuel, gas, co...   \n",
      "6   [scooter, razor, wheels, old, year, loves, yea...   \n",
      "7   [frisbee, throw, fun, ring, catch, aerobie, fl...   \n",
      "8   [mattress, air, camping, pump, inflate, sleepi...   \n",
      "9   [compass, bike, suunto, mirror, bikes, rack, u...   \n",
      "10  [knife, blade, knives, tool, sog, sharp, tools...   \n",
      "\n",
      "                                                  POS  \\\n",
      "0   [great, board, good, use, water, shorts, quali...   \n",
      "1   [stars, great, good, product, nice, price, exc...   \n",
      "2   [bands, resistance, band, door, great, set, wo...   \n",
      "3   [great, good, quality, product, price, old, ki...   \n",
      "4   [ball, soccer, net, goal, balls, basketball, g...   \n",
      "5   [stove, coleman, camping, flame, fuel, gas, co...   \n",
      "6   [scooter, razor, wheels, old, year, loves, sco...   \n",
      "7   [frisbee, fun, ring, aerobie, dog, easy, thing...   \n",
      "8   [mattress, air, camping, pump, comfortable, ma...   \n",
      "9   [compass, bike, suunto, mirror, bikes, rack, u...   \n",
      "10  [knife, blade, knives, tool, sog, sharp, tools...   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [This is one of my favorite things I have ever...  \n",
      "1   [Five Stars A+++++++, Five Stars (:, Four Star...  \n",
      "2   [Good, but not great We purchased two sets of ...  \n",
      "3   [Pretty good. I bought this for my 4 year old ...  \n",
      "4   [Franklin Sports Soccer Ball This soccer ball ...  \n",
      "5   [Reliable little work horse Although I bought ...  \n",
      "6   [Great scooter! My 6 year old loves this one ....  \n",
      "7   [Easy to throw and catch! Like others have sta...  \n",
      "8   [Durable Air Mattress for Low Price Perfect va...  \n",
      "9   [This is an adequate compass. I teach map read...  \n",
      "10  [Extraordinarily Useful! I found an older used...  \n",
      "Topic -1: great, board, good, like, just, use, water, shorts, quality, whistle\n",
      "Topic 0: stars, stars great, stars good, great, great stars, good, stars works, product, product stars, stars nice\n",
      "Topic 1: bands, resistance, band, door, use, great, set, workout, product, handles\n",
      "Topic 2: great, good, quality, product, price, love, works, old, kids, loves\n",
      "Topic 3: ball, soccer, net, goal, balls, basketball, great, practice, good, soccer ball\n",
      "Topic 4: stove, coleman, camping, flame, fuel, gas, cooking, burner, camp, use\n",
      "Topic 5: scooter, razor, wheels, old, year, loves, year old, scooters, ride, kids\n",
      "Topic 6: frisbee, throw, fun, ring, catch, aerobie, fly, flies, dog, far\n",
      "Topic 7: mattress, air, camping, pump, inflate, sleeping, comfortable, mattresses, air mattress, tent\n",
      "Topic 8: compass, bike, suunto, mirror, bikes, rack, use, accurate, computer, read\n",
      "Topic 9: knife, blade, knives, tool, sog, sharp, tools, pocket, swiss, great\n",
      "Topic 10: goggles, swim, fit, swimming, fog, water, pair, speedo, face, comfortable\n",
      "Topic 11: pads, fit, old, year, elbow, skates, year old, knee, protection, knees\n",
      "Topic 12: binoculars, focus, pair, price, bushnell, bird, great, good, watching, easy\n",
      "Topic 13: scope, scopes, 22, rifle, tasco, money, bushnell, good, clear, yards\n",
      "Topic 14: mat, yoga, mats, floor, exercise, exercises, great mat, folds, just, use\n",
      "Topic 15: boat, raft, pool, kids, oars, fun, river, pump, lake, small\n"
     ]
    }
   ],
   "source": [
    "print(bert_model.get_topic_info()[:11])\n",
    "top_words = bert_model.get_topics()\n",
    "\n",
    "# Print the top words for each topic\n",
    "for topic_id, words in top_words.items():\n",
    "    words = [word[0] for word in words]\n",
    "    print(f\"Topic {topic_id}: {', '.join(words)}\")\n",
    "\n",
    "# # Assign topics to documents\n",
    "# for i, topic in enumerate(topics):\n",
    "#     print(f\"Document {i + 1} is assigned to Topic {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp2023v2]",
   "language": "python",
   "name": "conda-env-nlp2023v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

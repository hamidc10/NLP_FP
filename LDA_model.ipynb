{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f0639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-20 19:31:08--  https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Electronics_5.json.gz\n",
      "Resolving datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)... 132.239.8.30\n",
      "Connecting to datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)|132.239.8.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1251876861 (1.2G) [application/x-gzip]\n",
      "Saving to: ‘Electronics_5.json.gz’\n",
      "\n",
      "100%[====================================>] 1,251,876,861 28.5MB/s   in 40s    \n",
      "\n",
      "2023-11-20 19:31:49 (29.6 MB/s) - ‘Electronics_5.json.gz’ saved [1251876861/1251876861]\n",
      "\n",
      "finished_eletric\n",
      "added_home_lst\n",
      "added_sports_lst\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import nltk\n",
    "import gzip\n",
    "import json\n",
    "import gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from pprint import pprint\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from tokenizers.pre_tokenizers import Sequence ,Whitespace, Punctuation\n",
    "\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "\n",
    "### Downloads ###\n",
    "# nltk.download('brown')\n",
    "# !pip install pyLDAvis\n",
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Gift_Cards_5.json.gz       'Gift_Cards_5.json.gz'\n",
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Books_5.json.gz\n",
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Home_and_Kitchen_5.json.gz\n",
    "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Sports_and_Outdoors_5.json.gz\n",
    "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Electronics_5.json.gz\n",
    "# ### ######### ###\n",
    "\n",
    "chunk_size=5 * 1024 * 1024 \n",
    " \n",
    "# with gzip.open(\"Sports_and_Outdoors_5.json.gz\", 'rb') as f:\n",
    "#     with open(\"Sports_and_Outdoors_5.json\", 'wb') as f_out:\n",
    "#         while True:\n",
    "#             chunk = f.read(chunk_size)\n",
    "#             if not chunk:\n",
    "#                 break\n",
    "#             f_out.write(chunk)\n",
    "# print(\"finished_sports\")\n",
    "# with gzip.open(\"Home_and_Kitchen_5.json.gz\", 'rb') as f:\n",
    "#     with open(\"Home_and_Kitchen_5.json\", 'wb') as f_out:\n",
    "#         while True:\n",
    "#             chunk = f.read(chunk_size)\n",
    "#             if not chunk:\n",
    "#                 break\n",
    "#             f_out.write(chunk)\n",
    "# print(\"finished_Home\")\n",
    "\n",
    "# with gzip.open(\"Books_5.json.gz\", 'rb') as f:\n",
    "#     with open(\"Books_5.json\", 'wb') as f_out:\n",
    "#         while True:\n",
    "#             chunk = f.read(chunk_size)\n",
    "#             if not chunk:\n",
    "#                 break\n",
    "#             f_out.write(chunk)\n",
    "# print(\"finished_books\")\n",
    "\n",
    "with gzip.open(\"Electronics_5.json.gz\", 'rb') as f:\n",
    "    with open(\"Electronics_5.json\", 'wb') as f_out:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            f_out.write(chunk)\n",
    "print(\"finished_eletric\")\n",
    " \n",
    "\n",
    "training_data_outdoors = []\n",
    "training_data_kitchen=[]\n",
    "# training_data_books = []\n",
    "# training_data_electronics = []\n",
    "\n",
    "     \n",
    "with open('Home_and_Kitchen_5.json') as f:\n",
    "    for l in f:\n",
    "        training_data_kitchen.append(json.loads(l.strip()))\n",
    "print(\"added_home_lst\")\n",
    "with open('Sports_and_Outdoors_5.json') as f:\n",
    "    for l in f:\n",
    "        training_data_outdoors.append(json.loads(l.strip()))\n",
    "print(\"added_sports_lst\")      \n",
    "\n",
    "# with open('Books_5.json') as f:\n",
    "#     for l in f:\n",
    "#         training_data_books.append(json.loads(l.strip()))\n",
    "# print(\"added_books_lst\")           \n",
    "# with open('Electronics_5.json') as f:\n",
    "#     for l in f:\n",
    "#         training_data_electronics.append(json.loads(l.strip()))\n",
    "        \n",
    "complete_test=[]\n",
    "complete_test.extend(training_data_outdoors[:int(0.8*len(training_data_outdoors))])\n",
    "complete_test.extend(training_data_kitchen[:int(0.8*len(training_data_kitchen))])\n",
    "#complete_test.extend(training_data_books[:int(0.8*len(training_data_books))])\n",
    "# complete_test.extend(training_data_electronics[:int(0.8*len(training_data_electronics))])\n",
    "\n",
    "\n",
    "simplified_data=[]\n",
    "for i in range(len(complete_test)):\n",
    "    simplified_data.append(complete_test[i].get(\"summary\",'')+' '+complete_test[i].get(\"reviewText\",''))\n",
    "# print(len(simplified_data))\n",
    "\n",
    "\n",
    "def sent_to_words(data):\n",
    "    for obj in data:\n",
    "        yield(gensim.utils.simple_preprocess(str(obj), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "\n",
    "def stopwordscleaner(data):\n",
    "    stp = set(stopwords.words('english'))\n",
    "    return [[tok for tok in obj if tok.lower() not in stp] for obj in data]\n",
    "    \n",
    "clean_words=sent_to_words(simplified_data)\n",
    "clean_data=stopwordscleaner(clean_words)\n",
    "\n",
    "\n",
    "id2word=corpora.Dictionary(clean_data)\n",
    "reviews=clean_data\n",
    "review_corpus=[id2word.doc2bow(review) for review in reviews]\n",
    "\n",
    "topic=200\n",
    "lda=gensim.models.ldamulticore.LdaMulticore(corpus=review_corpus,id2word=id2word,num_topics=topic,workers=4)\n",
    "# pprint(lda.print_topics())\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda, review_corpus, id2word)\n",
    "pyLDAvis.save_html(LDAvis_prepared,'lda_model'+'.html')\n",
    "LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
